{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import excellaint as ea\n",
    "\n",
    "test_file = \"/Users/ct6g18/Python/ExcellAint/test/test_data/2_digit_yr.xlsx\"\n",
    "\n",
    "df = pd.read_excel(test_file)\n",
    "\n",
    "df[\"pd_read_dates\"] = pd.to_datetime(df[\"mangled_dates\"])\n",
    "\n",
    "df.iloc[280:295]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to me like the best way to tackle this problem is to first split the string using the datetime_separator. This then gives us separate date and time columns. \n",
    "\n",
    "I'm going to ignore anything subsecond for now, because I'd rather focus on the dates, rather than the times - and I think that the dates are more likely to be the source of the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ea.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames_init = df.columns.tolist()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_datetimes(df : pl.DataFrame | pd.DataFrame\n",
    "                   ,datetime_col : str = \"mangled_dates\"\n",
    "                   ,datetime_sep : str = ea.config.datetime_sep\n",
    "                   ) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Type union between pl.Dataframe and pd.DataFrame should be removed.\n",
    "\n",
    "    To be honest, I haven't got a particularly good idea as to how this works. I\n",
    "    copied it from stackoverflow \n",
    "    (https://stackoverflow.com/questions/73699500/python-polars-split-string-column-into-many-columns-by-delimiter)\n",
    "    and it seems to do what I wanted.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(df, pl.DataFrame):\n",
    "        pass\n",
    "    elif isinstance(df, pd.DataFrame):\n",
    "        df = pl.from_pandas(df)\n",
    "    else:\n",
    "        raise ValueError(\"df must be a pandas or polars DataFrame\")\n",
    "\n",
    "    return (\n",
    "        df\n",
    "        .with_columns(\n",
    "            pl.col(\"mangled_dates\").str.split(ea.config.datetime_sep)\n",
    "                                    .alias(\"[date,time]\"))\n",
    "        .explode(\"[date,time]\")\n",
    "        .with_columns(\n",
    "            (\"string_\" + pl.arange(0, pl.len()).cast(pl.Utf8).str.zfill(2))\n",
    "            .over(\"row_id\")\n",
    "            .alias(\"col_nm\")\n",
    "        )\n",
    "        .pivot(\n",
    "            index=['row_id', 'mangled_dates'],\n",
    "            values='[date,time]',\n",
    "            columns='col_nm',\n",
    "        )\n",
    "        .rename(\n",
    "            {\n",
    "                \"string_00\": \"date_str\",\n",
    "                \"string_01\": \"time_str\"\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def convert_time(df : pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Takes the time column and converts it to a time object.\n",
    "\n",
    "    This is somewhat less ambiguous than splitting dates up, so I'm going to \n",
    "    keep it simple for now so we can resolve the main issue\n",
    "    \"\"\"\n",
    "    return (\n",
    "        df.with_columns(\n",
    "            pl.col(\"time_str\")\n",
    "            .str\n",
    "            .to_time(f\"%H{ea.config.time_sep}%M\")\n",
    "            .alias(\"Time\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "df = split_datetimes(df)\n",
    "\n",
    "df = convert_time(df)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ea.config.date_sep = \"/\"\n",
    "# This is just a retread of the above, except now using the datetime splitter\n",
    "def split_dates(df : pl.DataFrame | pd.DataFrame\n",
    "               ,datetime_col : str = \"mangled_dates\"\n",
    "               ,datetime_sep : str = ea.config.datetime_sep\n",
    "               ) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Type union between pl.Dataframe and pd.DataFrame should be removed.\n",
    "\n",
    "    To be honest, I haven't got a particularly good idea as to how this works. I\n",
    "    copied it from stackoverflow \n",
    "    (https://stackoverflow.com/questions/73699500/python-polars-split-string-column-into-many-columns-by-delimiter)\n",
    "    and it seems to do what I wanted.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(df, pl.DataFrame):\n",
    "        pass\n",
    "    elif isinstance(df, pd.DataFrame):\n",
    "        df = pl.from_pandas(df)\n",
    "    else:\n",
    "        raise ValueError(\"df must be a pandas or polars DataFrame\")\n",
    "\n",
    "    return (\n",
    "        df\n",
    "        .with_columns(\n",
    "            pl.col(datetime_col).str.split(ea.config.date_sep)\n",
    "                                    .alias(\"[date]\"))\n",
    "        .explode(\"[date]\")\n",
    "        .with_columns(\n",
    "            (pl.arange(0, pl.len()))\n",
    "            .over(\"row_id\")\n",
    "            .alias(\"col_nm\")\n",
    "        )\n",
    "        .pivot(\n",
    "            index=['row_id', 'mangled_dates','Time'],\n",
    "# We can make this more robust in the future by working out all the columns other \n",
    "# than the column we want to split\n",
    "            values='[date]',\n",
    "            columns='col_nm',\n",
    "        )\n",
    "    )   \n",
    "\n",
    "df = split_dates(df,datetime_col=\"date_str\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heres the plan:\n",
    "\n",
    "From the above, we can clearly see that 'string_00' is a days column, 'string_01' is a months column, and 'string_02' is a years column.\n",
    "\n",
    "What heuristics am I using to do this? \n",
    "\n",
    "- I can see that the dates are all in the range 1-31. \n",
    "- I can see that the months are all in the range 1-12.\n",
    "- Years are a bit secondary, because its not obvious. I'm going to use the heuristic that for years with 4 digits, the first two digits are 19 or 20. For years with 2 digits, the year is in the range 0-99. If the year is 2 digits and less than 24, I'm going to assume that the year is 20xx. If the year is 2 digits and greater than 24, I'm going to assume that the year is 19xx. This is a bit of a guess, but I think it's a reasonable one.\n",
    "\n",
    "So we first need to get some statistics on our remaining columns to split, and then we need to assign a level of confidence to which are the days, months, and years columns. \n",
    "\n",
    "Maaaybe we could come back and use some machine learning stuff for this, but for now I think we can do it manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars.selectors as cs\n",
    "import warnings\n",
    "\n",
    "cols_to_process = [col for col in df.select(cs.by_dtype(pl.Utf8)).columns if col not in colnames_init]\n",
    "\n",
    "for col in cols_to_process:\n",
    "    print(col)\n",
    "\n",
    "# Now we need to get some of the relevant statistics on our columns.\n",
    "\n",
    "# First thing to do is get the max character width of them all\n",
    "processing_df = df.select(*cols_to_process)\n",
    "\n",
    "max_chars_dict = processing_df.with_columns(\n",
    "    [pl.col(colname).str.len_chars().max() for colname in cols_to_process]\n",
    ").max().to_dict(as_series=False)\n",
    "\n",
    "max_chars_dict = {\n",
    "    key : val[0] if val else None for key,val in max_chars_dict.items()\n",
    "}\n",
    "\n",
    "\n",
    "max_val_dict = processing_df.with_columns(\n",
    "    [pl.col(colname).cast(pl.Int32).max() for colname in cols_to_process]\n",
    ").max().to_dict(as_series=False)\n",
    "\n",
    "max_val_dict = {\n",
    "    key : val[0] if val else None for key,val in max_val_dict.items()\n",
    "}\n",
    "\n",
    "def assign_datetype(cols_to_process : list[str]\n",
    "                   ,max_chars_dict : dict[str,int]\n",
    "                   ,max_val_dict : dict[str,int]\n",
    "                   ) -> dict[str,str]:\n",
    "    \"\"\"\n",
    "    This function takes the columns to process, the maximum number of characters\n",
    "    in each column and the maximum value in each column and returns a dictionary\n",
    "    of the `date data` types of each column:\n",
    "        - Year \n",
    "        - Month\n",
    "        - Day\n",
    "    \"\"\"\n",
    "    available_date_data_types = { \n",
    "        \"Year\",\n",
    "        \"Month\",\n",
    "        \"Day\",\n",
    "    }\n",
    "\n",
    "    mappings = {\n",
    "        \"Year\" : None,\n",
    "        \"Month\" : None,\n",
    "        \"Day\" : None,\n",
    "    }\n",
    "\n",
    "    for key, val in max_chars_dict.items():\n",
    "        if val == 4:\n",
    "            mappings[\"Year\"] = int(key)\n",
    "            available_date_data_types.remove(\"Year\")\n",
    "\n",
    "            if not ea.config.allow_monthfirst:\n",
    "                mappings[\"Day\"] = 2 - mappings[\"Year\"]\n",
    "                mappings[\"Month\"] = 1\n",
    "\n",
    "                available_date_data_types.remove(\"Day\")\n",
    "                available_date_data_types.remove(\"Month\")\n",
    "                break\n",
    "            \n",
    "            else:\n",
    "                raise NotImplementedError(\"Only an instance with a four digit year is supported at the moment.\")\n",
    "\n",
    "\n",
    "    if len(available_date_data_types) > 0:\n",
    "        raise AssertionError(f\"Could not assign all date data types. Remaining: {available_date_data_types}. Please check the data.\")\n",
    "\n",
    "    mappings = {str(val) : key for key, val in mappings.items()}\n",
    "\n",
    "    warnings.warn(\"Did not use the following arguments: {max_val_dict}, {cols_to_process}.\"\n",
    "                  \" We probably need to make this function a bit smarter.\"\n",
    "                  ,stacklevel=2)\n",
    "\n",
    "    return mappings\n",
    "        \n",
    "mappings = assign_datetype(cols_to_process,max_chars_dict,max_val_dict)\n",
    "\n",
    "df = df.rename(mappings)\n",
    "\n",
    "df = df.with_columns(\n",
    "    pl.col(\"Day\").cast(pl.Int32),\n",
    "    pl.col(\"Month\").cast(pl.Int32),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def year_to_int(df : pl.DataFrame\n",
    "                ,year_col : str = \"Year\"\n",
    "                ) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    This gets a bit stupid, because we need to generate a new column which is a\n",
    "    boolean: is the year column four characters. If so, we can cast it to an int.\n",
    "    If not, we want to check if the two characters we have are less than or equal \n",
    "    to the current year. If so, we prepend \"20\". If not, we prepend \"19\".\n",
    "    \"\"\"\n",
    "\n",
    "    # Spoof the current year\n",
    "\n",
    "    CURRENT_YEAR = 24\n",
    "\n",
    "    df = df.with_columns(\n",
    "        pl.col(\"Year\").str.len_chars().alias(\"year_len\")\n",
    "    )\n",
    "\n",
    "    df = df.with_columns(\n",
    "        pl.when(pl.col(\"year_len\") == 4)\n",
    "          .then(pl.col(\"Year\").cast(pl.Int32))\n",
    "          .otherwise(\n",
    "            pl.col(\"Year\")\n",
    "          ).alias(\"Year\")\n",
    "    )\n",
    "\n",
    "    df = df.with_columns(\n",
    "        pl.when(pl.col(\"year_len\") == 2)\n",
    "        .then(\n",
    "            pl.when(pl.col(\"Year\").cast(pl.Int32) <= CURRENT_YEAR)\n",
    "            .then(pl.lit(\"20\"))\n",
    "            .otherwise(pl.lit(\"19\"))\n",
    "           )\n",
    "        .otherwise(pl.lit(\"\"))\n",
    "        .alias(\"prepend_col\")\n",
    "    )\n",
    "\n",
    "    df = df.with_columns(\n",
    "        (pl.col(\"prepend_col\") + pl.col(\"Year\").alias(\"Year\"))\n",
    "        .cast(pl.Int32)\n",
    "        .alias(\"Year\")\n",
    "    )\n",
    "\n",
    "    df = df.drop(\"year_len\",\"prepend_col\")\n",
    "\n",
    "    return df.with_columns(\n",
    "        pl.col(year_col).cast(pl.Int32)\n",
    "    )\n",
    "\n",
    "\n",
    "df = year_to_int(df)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_date_cols(df : pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    This function takes a dataframe with date columns and a time column and \n",
    "    combines them into a datetime column. Since the names are all set by the \n",
    "    previous functions we can keep things really constrained\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.with_columns(\n",
    "        pl.date(\n",
    "            pl.col(\"Year\"),\n",
    "            pl.col(\"Month\"),\n",
    "            pl.col(\"Day\"),\n",
    "        ).alias(\"Date\")\n",
    "        )\n",
    "\n",
    "    return df\n",
    "\n",
    "def combine_datetime_cols(df : pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Combine our date and our time column\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.with_columns(\n",
    "        pl.datetime(\n",
    "            pl.col(\"Date\").dt.year(),\n",
    "            pl.col(\"Date\").dt.month(),\n",
    "            pl.col(\"Date\").dt.day(),\n",
    "            pl.col(\"Time\").dt.hour(),\n",
    "            pl.col(\"Time\").dt.minute(),\n",
    "            pl.col(\"Time\").dt.second(),\n",
    "        ).alias(\"Datetime\")\n",
    "        )\n",
    "\n",
    "    df = df.drop(\"Date\",\"Time\",\"Year\",\"Month\",\"Day\")\n",
    "\n",
    "    return df\n",
    "\n",
    "df = combine_date_cols(df)\n",
    "df = combine_datetime_cols(df)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pandas().plot(y=\"row_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Long story short - it works in this specific instance. Now we just need to pull out the logic and we can get to business.\n",
    "\n",
    "\n",
    "- After that - refactoring and speeding things up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          mangled_dates  row_id\n",
      "0        01/01/20 12:00       0\n",
      "1        01/01/20 01:00       1\n",
      "2        01/01/20 02:00       2\n",
      "3        01/01/20 03:00       3\n",
      "4        01/01/20 04:00       4\n",
      "...                 ...     ...\n",
      "17539  31/12/2021 19:00   17539\n",
      "17540  31/12/2021 20:00   17540\n",
      "17541  31/12/2021 21:00   17541\n",
      "17542  31/12/2021 22:00   17542\n",
      "17543  31/12/2021 23:00   17543\n",
      "\n",
      "[17544 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import excellaint as ea\n",
    "import pandas as pd\n",
    "\n",
    "ea.config.date_sep = \"/\"\n",
    "ea.config.datetime_sep = \" \"\n",
    "\n",
    "\n",
    "test_file = \"/Users/ct6g18/Python/ExcellAint/test/test_data/2_digit_yr.xlsx\"\n",
    "\n",
    "test_df = pd.read_excel(test_file)\n",
    "\n",
    "print(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ct6g18/Python/ExcellAint/src/excellaint/excellaint.py:80: UserWarning: Did not use the following arguments: {max_val_dict}, {cols_to_process}. We probably need to make this function a bit smarter.\n",
      "  mappings = assign_datetype(config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.5 ms ± 2.19 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "ea.parse_datetime_column(test_df,\"mangled_dates\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "excellaint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
